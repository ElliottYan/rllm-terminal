# SWE æ•°æ®å‡†å¤‡é—®é¢˜è§£å†³æ–¹æ¡ˆå¯¹æ¯”

## é”™è¯¯åŸå› 

```
pyarrow.lib.ArrowNotImplementedError: Nested data conversions not implemented for chunked array outputs
```

è¿™ä¸ªé”™è¯¯å‘ç”Ÿåœ¨è¯»å– `train_verl.parquet` æ—¶ï¼Œå› ä¸º `apply_verl_postprocessing` åˆ›å»ºäº†åµŒå¥—ç»“æ„ï¼š

```python
{
    "prompt": [{"role": "user", "content": "placeholder"}],  # åˆ—è¡¨åµŒå¥—å­—å…¸
    "reward_model": {"style": "rule", "ground_truth": None},  # åµŒå¥—å­—å…¸
    "extra_info": entry,  # åµŒå¥—å­—å…¸ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
}
```

PyArrow æ— æ³•å¤„ç†è¿™ç§æ·±åº¦åµŒå¥—çš„ç»“æ„ã€‚

---

## æ–¹æ¡ˆ 1ï¼šä¿®å¤ `apply_verl_postprocessing`ï¼ˆâœ… æ¨èï¼‰

### ä¿®æ”¹å†…å®¹

ä¿®æ”¹ `rllm/data/dataset.py` ä¸­çš„ `apply_verl_postprocessing` æ–¹æ³•ï¼Œå°†åµŒå¥—ç»“æ„åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼š

```python
@classmethod
def apply_verl_postprocessing(cls, data: list[dict[str, Any]]) -> list[dict[str, Any]]:
    processed_data = []
    for entry in data:
        processed_entry = {
            "prompt": json.dumps([{"role": "user", "content": "placeholder"}]),
            "reward_model": json.dumps({
                "style": "rule",
                "ground_truth": entry.get("ground_truth", None),
            }),
            "extra_info": json.dumps(entry),
        }
        processed_data.append(processed_entry)
    return processed_data
```

### ä¼˜ç‚¹

1. âœ… **ä¸€åŠ³æ°¸é€¸**ï¼šä¿®å¤åï¼Œæ‰€æœ‰æ•°æ®é›†éƒ½ä¸ä¼šå†é‡åˆ°è¿™ä¸ªé—®é¢˜
2. âœ… **ä¿æŒä¸€è‡´æ€§**ï¼šæ‰€æœ‰æ•°æ®é›†ç»§ç»­ä½¿ç”¨ `DatasetRegistry`
3. âœ… **æ­£ç¡®çš„ä¿®å¤**ï¼šåœ¨æ¡†æ¶å±‚é¢è§£å†³ bug
4. âœ… **å‘åå…¼å®¹**ï¼šè¯»å–æ•°æ®æ—¶ `json.loads()` å³å¯è¿˜åŸ

### ç¼ºç‚¹

1. âŒ éœ€è¦ä¿®æ”¹æ ¸å¿ƒæ¡†æ¶ä»£ç 
2. âŒ éœ€è¦é‡æ–°ç”Ÿæˆæ‰€æœ‰å·²å­˜åœ¨çš„ verl parquet æ–‡ä»¶

### ä½¿ç”¨æ–¹å¼

```python
from rllm.data.dataset import DatasetRegistry

# æ³¨å†Œæ•°æ®é›†ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼‰
train_dataset = DatasetRegistry.register_dataset("R2E_Gym_Subset", train_data, "train")

# åŠ è½½æ•°æ®
dataset = DatasetRegistry.load_dataset('R2E_Gym_Subset', 'train')

# è¯»å– verl æ–‡ä»¶ï¼ˆéœ€è¦ååºåˆ—åŒ–ï¼‰
import pandas as pd
import json

verl_path = dataset.get_verl_data_path()
df = pd.read_parquet(verl_path)

# è§£æ JSON å­—æ®µ
prompt = json.loads(df.iloc[0]['prompt'])
reward_model = json.loads(df.iloc[0]['reward_model'])
extra_info = json.loads(df.iloc[0]['extra_info'])
```

---

## æ–¹æ¡ˆ 2ï¼šä¸ä½¿ç”¨ DatasetRegistryï¼ˆâš ï¸ æ›¿ä»£æ–¹æ¡ˆï¼‰

### ä¿®æ”¹å†…å®¹

åˆ›å»ºæ–°è„šæœ¬ `prepare_swe_data_direct.py`ï¼Œç›´æ¥ä¿å­˜ parquet æ–‡ä»¶ï¼Œä¸ä½¿ç”¨ `DatasetRegistry`ã€‚

### ä¼˜ç‚¹

1. âœ… **ä¸ä¿®æ”¹æ¡†æ¶**ï¼šä¸è§¦ç¢°æ ¸å¿ƒä»£ç 
2. âœ… **å®Œå…¨æ§åˆ¶**ï¼šè‡ªå·±å†³å®šæ•°æ®æ ¼å¼
3. âœ… **å‚è€ƒå®ç°**ï¼šä¸ `scripts/data/swe_dataset.py` ä¸€è‡´

### ç¼ºç‚¹

1. âŒ **å¤±å»ç»Ÿä¸€ç®¡ç†**ï¼šæ•°æ®ä¸åœ¨ `dataset_registry.json` ä¸­æ³¨å†Œ
2. âŒ **æ— æ³•ä½¿ç”¨ DatasetRegistry API**ï¼šä¸èƒ½ç”¨ `load_dataset()` ç­‰æ–¹æ³•
3. âŒ **éœ€è¦æ‰‹åŠ¨ç®¡ç†è·¯å¾„**ï¼šè®­ç»ƒæ—¶éœ€è¦æŒ‡å®šå®Œæ•´è·¯å¾„
4. âŒ **ä¸ä¸€è‡´**ï¼šä¸å…¶ä»–æ•°æ®é›†çš„ä½¿ç”¨æ–¹å¼ä¸åŒ

### ä½¿ç”¨æ–¹å¼

```bash
# ç”Ÿæˆæ•°æ®
cd examples/swe
python prepare_swe_data_direct.py --output_dir ../../data/swe
```

```python
# è¯»å–æ•°æ®ï¼ˆç›´æ¥ç”¨ pandasï¼‰
import pandas as pd
import json

df = pd.read_parquet("data/swe/R2E_Gym_Subset_train.parquet")

# è§£æ JSON å­—æ®µ
prompt = json.loads(df.iloc[0]['prompt'])
reward_model = json.loads(df.iloc[0]['reward_model'])
extra_info = json.loads(df.iloc[0]['extra_info'])
```

---

## å¯¹æ¯”æ€»ç»“

| ç»´åº¦ | æ–¹æ¡ˆ 1ï¼šä¿®å¤æ¡†æ¶ | æ–¹æ¡ˆ 2ï¼šç›´æ¥ä¿å­˜ |
|------|----------------|----------------|
| **è§£å†³é—®é¢˜** | âœ… å½»åº•è§£å†³ | âœ… ç»•è¿‡é—®é¢˜ |
| **ä¿®æ”¹æ¡†æ¶** | âŒ éœ€è¦ | âœ… ä¸éœ€è¦ |
| **ç»Ÿä¸€ç®¡ç†** | âœ… æ˜¯ | âŒ å¦ |
| **ä½¿ç”¨ä¾¿åˆ©** | âœ… é«˜ | âš ï¸ ä¸­ |
| **é•¿æœŸç»´æŠ¤** | âœ… å¥½ | âš ï¸ éœ€é¢å¤–ç»´æŠ¤ |
| **å½±å“èŒƒå›´** | âš ï¸ æ‰€æœ‰æ•°æ®é›† | âœ… ä»… SWE |

---

## å»ºè®®

### ğŸ¯ æ¨èæ–¹æ¡ˆ 1

**ç†ç”±ï¼š**

1. è¿™æ˜¯ä¸€ä¸ª**æ¡†æ¶ bug**ï¼Œä¸æ˜¯ä½¿ç”¨é—®é¢˜
2. PyArrow æ— æ³•å¤„ç†åµŒå¥—ç»“æ„æ˜¯å·²çŸ¥é™åˆ¶
3. ä¿®å¤åæ‰€æœ‰æ•°æ®é›†å—ç›Šï¼Œä¸ä¼šå†å‡ºç°è¿™ä¸ªé”™è¯¯
4. åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²æ˜¯æ ‡å‡†åšæ³•ï¼ˆå‚è€ƒ `scripts/data/swe_dataset.py`ï¼‰

**ä¿®å¤åéœ€è¦åšçš„ï¼š**

```bash
# 1. åˆ é™¤æ—§çš„ verl æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
rm -rf rllm/data/datasets/*/train_verl.parquet
rm -rf rllm/data/datasets/*/test_verl.parquet

# 2. é‡æ–°ç”Ÿæˆæ•°æ®
cd examples/swe
python prepare_swe_data.py
```

### ğŸ”„ ä½•æ—¶ä½¿ç”¨æ–¹æ¡ˆ 2

ä»…åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ä½¿ç”¨ï¼š

- ä½ ç¡®å®ä¸èƒ½/ä¸æƒ³ä¿®æ”¹æ¡†æ¶ä»£ç 
- ä½ åªéœ€è¦ä¸´æ—¶å¤„ç† SWE æ•°æ®
- ä½ çš„è®­ç»ƒè„šæœ¬å·²ç»é€‚é…äº†ç›´æ¥è¯»å– parquet çš„æ–¹å¼

---

## æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆåµŒå¥—ç»“æ„ä¼šå¯¼è‡´é—®é¢˜ï¼Ÿ

Parquet æ˜¯åˆ—å¼å­˜å‚¨æ ¼å¼ï¼Œå¯¹åµŒå¥—ç»“æ„çš„æ”¯æŒæœ‰é™ï¼š

1. **ç®€å•åµŒå¥—**ï¼ˆlist<int>ï¼‰ï¼šæ”¯æŒ
2. **struct ç±»å‹**ï¼ˆä¸€å±‚å­—å…¸ï¼‰ï¼šæ”¯æŒ
3. **å¤æ‚åµŒå¥—**ï¼ˆlist<struct<...>>ï¼‰ï¼šéƒ¨åˆ†æ”¯æŒ
4. **æ·±åº¦åµŒå¥—**ï¼ˆdict<list<dict<...>>>ï¼‰ï¼šâŒ ä¸æ”¯æŒ

`apply_verl_postprocessing` åˆ›å»ºçš„ç»“æ„å±äºç¬¬ 4 ç±»ï¼ŒPyArrow æ— æ³•å¤„ç†ã€‚

### ä¸ºä»€ä¹ˆåºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²å¯ä»¥è§£å†³ï¼Ÿ

```python
# åŸæ¥ï¼šå¤æ‚åµŒå¥—ï¼ˆPyArrow æ— æ³•å¤„ç†ï¼‰
{"prompt": [{"role": "user", "content": "..."}]}

# ç°åœ¨ï¼šç®€å•å­—ç¬¦ä¸²ï¼ˆPyArrow å®Œå…¨æ”¯æŒï¼‰
{"prompt": '{"role": "user", "content": "..."}'}
```

å­—ç¬¦ä¸²æ˜¯ parquet çš„åŸºæœ¬ç±»å‹ï¼Œå®Œå…¨æ”¯æŒã€‚

---

## éªŒè¯ä¿®å¤

ä¿®å¤åï¼Œè¿è¡Œæµ‹è¯•ï¼š

```bash
cd examples/swe
python test_prepare_swe.py
```

åº”è¯¥çœ‹åˆ°ï¼š

```
âœ“ Successfully read parquet file
âœ“ All JSON fields are valid
```

è€Œä¸æ˜¯ï¼š

```
âœ— ArrowNotImplementedError: Nested data conversions not implemented
```
